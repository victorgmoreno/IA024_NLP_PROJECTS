{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de sentimento por Engenharia de Prompts\n",
    "\n",
    "- Utilizar o groq.com para usar a API do Llama 3 70B para fazer análise de sentimentos do IMDB. É um enunciado bem livre e vamos acompanhando durante a semana em função dos resultados parciais que vocês conseguem fazer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorgmoreno/miniconda3/envs/ia024/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from groq import Groq\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset\n",
    "\n",
    "I am going to use the IMDB dataset and its partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDb movie reviews dataset\n",
    "train_dataset_full = load_dataset('imdb', split='train')\n",
    "test_dataset_full = load_dataset('imdb', split='test')\n",
    "test_dataset_full  = test_dataset_full.shuffle(seed=42).select(range(1000)) # avaliação com 1000 amostras aleatórias do conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting positives from index 11112 to 12111 and 23612 to 24612\n",
    "train_dataset = train_dataset_full.select(list(range(11112, 11575)) + list(range(23612, 24075)))\n",
    "train_dataset = train_dataset.shuffle(seed=42).select(range(len(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Amostras: 926\n",
      "Quantidade de Amostras Positivas: 463\n",
      "Quantidade de Amostras Negativas: 463\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de Amostras:', len(train_dataset))\n",
    "print('Quantidade de Amostras Positivas:', sum(1 for label in train_dataset['label'] if label == 1))\n",
    "print('Quantidade de Amostras Negativas:', sum(1 for label in train_dataset['label'] if label == 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Groq\n",
    "\n",
    "Groq's API stands out for its speed and efficiency, making it a viable option for developers looking to implement real-time interactions with LLMs in their applications. To use the Groq API, developers need to install the relevant client libraries and set up their API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Client Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Test Groq\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Groq Llama 3 to Sentiment Aanlysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(review, prompt):\n",
    "    # organizing prompt\n",
    "    prompt = f\"\"\"{prompt}. This is the movie review: '{review}'. \"\"\"\n",
    "    \n",
    "    # Chamando a API com o prompt\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        model=\"llama3-70b-8192\")\n",
    "        \n",
    "    # Retornando a resposta do modelo\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prompt Engineering\n",
    "\n",
    "Here are 3 types of prompts with different types of structures. The goal of this code is to compare their accuracy results based on the different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_zero_shot = \"\"\"Your task is to analyse the sentiment of the movie review and classify if it is 'positive' or 'negative'. Your answer MUST be ONLY one word, either 'positive' or 'negative', nothing else.\n",
    "    Is the following movie review positive or negative?\"\"\"\n",
    "\n",
    "prompt_few_shot = \"\"\"Your task is to analyse the sentiment of the movie review and classify if it is 'positive' or 'negative'. Your answer MUST be ONLY one word, either 'positive' or 'negative', nothing else.\n",
    "    Below are four examples to guide your understanding:\n",
    "    Review 1: \"This movie is very bad. I did not like it.\" - Sentiment: \"negative\"\n",
    "    Review 2: \"This movie is very good. I've loved it.\" - Sentiment: \"positive\"\n",
    "    Review 3: \"Terrible movie. Nuff Said.<br /><br />These Lines are Just Filler. The movie was bad. Why I have to expand on that I don't know. This is already a waste of my time. I just wanted to warn others. Avoid this movie. The acting sucks and the writing is just moronic. Bad in every way. The only nice thing about the movie are Deniz Akkaya's breasts. Even that was ruined though by a terrible and unneeded rape scene. The movie is a poorly contrived and totally unbelievable piece of garbage.<br /><br />OK now I am just going to rag on IMDb for this stupid rule of 10 lines of text minimum. First I waste my time watching this offal. Then feeling compelled to warn others I create an account with IMDb only to discover that I have to write a friggen essay on the film just to express how bad I think it is. Totally unnecessary.\" - Sentiment: \"negative\"\n",
    "    Review 4: \"I can't remember many films where a bumbling idiot of a hero was so funny throughout. Leslie Cheung is such the antithesis of a hero that he's too dense to be seduced by a gorgeous vampire... I had the good luck to see it on a big screen, and to find a video to watch again and again.\" - Sentiment: \"positive\" \n",
    "    Now is your turn. Is the following movie review positive or negative? \"\"\"\n",
    "\n",
    "prompt_chain_of_thought_cot = \"\"\"Your task is to analyse the sentiment of the movie review and classify if it is 'positive' or 'negative' using a step-by-step reasoning approach. Your answer MUST be ONLY one word, either 'positive' or 'negative', nothing else.\n",
    "    First, identify key words or phrases that indicate emotion or judgment. Next, assess whether these words have a positive or negative connotation. Finally, based on the predominance of positive or negative words, conclude the sentiment of the review.\n",
    "    Steps to follow:\n",
    "        1. Identification of sentiment-indicating keywords.\n",
    "        2. Evaluation of each keyword's sentiment connotation (positive or negative).\n",
    "        3. Conclusion based on the majority sentiment of keywords.\n",
    "        4. Classify if the final concluision is 'positive' or 'negative', and return only the class, nothing else.\n",
    "        \n",
    "    Below are four examples of the classification to guide your understanding:\n",
    "        Review 1: \"This movie is very bad. I did not like it.\" - Sentiment: \"negative\"\n",
    "        Review 2: \"This movie is very good. I've loved it.\" - Sentiment: \"positive\"\n",
    "        Review 3: \"Terrible movie. Nuff Said.<br /><br />These Lines are Just Filler. The movie was bad. Why I have to expand on that I don't know. This is already a waste of my time. I just wanted to warn others. Avoid this movie. The acting sucks and the writing is just moronic. Bad in every way. The only nice thing about the movie are Deniz Akkaya's breasts. Even that was ruined though by a terrible and unneeded rape scene. The movie is a poorly contrived and totally unbelievable piece of garbage.<br /><br />OK now I am just going to rag on IMDb for this stupid rule of 10 lines of text minimum. First I waste my time watching this offal. Then feeling compelled to warn others I create an account with IMDb only to discover that I have to write a friggen essay on the film just to express how bad I think it is. Totally unnecessary.\" - Sentiment: \"negative\"\n",
    "        Review 4: \"I can't remember many films where a bumbling idiot of a hero was so funny throughout. Leslie Cheung is such the antithesis of a hero that he's too dense to be seduced by a gorgeous vampire... I had the good luck to see it on a big screen, and to find a video to watch again and again.\" - Sentiment: \"positive\" \n",
    "        Now is your turn. Follow the steps and answer: Is the following movie review positive or negative? \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "review = \"The movie was normal! The story was little engaging and the characters were little well-developed.\"\n",
    "print(sentiment_analysis(review, prompt_chain_of_thought_cot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_without_bar(dataset, prompt):\n",
    "    predictions = [sentiment_analysis(review=review, prompt = prompt) for review in dataset['text']]\n",
    "    actual_labels = ['positive' if label == 1 else 'negative' for label in dataset['label']]\n",
    "    \n",
    "    correct_predictions = sum([pred == true for pred, true in zip(predictions, actual_labels)])\n",
    "    accuracy = correct_predictions*100 / len(dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(dataset, prompt):\n",
    "    \"\"\"Evaluates the accuracy of sentiment analysis on a dataset with a progress bar.\"\"\"\n",
    "    predictions = []\n",
    "    actual_labels = ['positive' if label == 1 else 'negative' for label in dataset['label']]\n",
    "    \n",
    "    # Process each review in the dataset and update the progress bar\n",
    "    for review in tqdm(dataset['text'], desc=\"Analyzing Sentiments\"):\n",
    "        prediction = sentiment_analysis(review=review, prompt=prompt)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    # Calculate the number of correct predictions\n",
    "    correct_predictions = sum(pred == true for pred, true in zip(predictions, actual_labels))\n",
    "    accuracy = correct_predictions * 100 / len(dataset)\n",
    "    return f\"{accuracy:.4f}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot Accuracy: 95.0500\n"
     ]
    }
   ],
   "source": [
    "# Calculando a acurácia Zero-Shot\n",
    "zeroshot_accuracy = evaluate_accuracy(train_dataset, prompt_zero_shot)\n",
    "print(f\"Zero-Shot Accuracy: {zeroshot_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Sentiments: 100%|██████████| 926/926 [1:14:44<00:00,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-Shot Accuracy: 94.6004%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculando a acurácia Few-Shot\n",
    "fewshot_accuracy = evaluate_accuracy(train_dataset, prompt_few_shot)\n",
    "print(f\"Few-Shot Accuracy: {fewshot_accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Sentiments: 100%|██████████| 926/926 [1:29:50<00:00,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-Thoughts Accuracy: 94.4924%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculando a acurácia Chain-of-Thoughts\n",
    "cot_accuracy = evaluate_accuracy(train_dataset, prompt_chain_of_thought_cot)\n",
    "print(f\"Chain-of-Thoughts Accuracy: {cot_accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia024_kernel",
   "language": "python",
   "name": "ia024_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
