{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import gdown\n",
    "import random\n",
    "import pickle\n",
    "import tarfile\n",
    "import warnings\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.documents import Document\n",
    "from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_relevancy\n",
    "import groq \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "llm = ChatGroq(temperature=0, groq_api_key=GROQ_API_KEY, model_name=\"llama3-70b-8192\")\n",
    "embedder = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de amostras do context_articles: 56550\n",
      "\n",
      "Quantidade de amostras do test_set: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 14594.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de questões: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Evaluating: 100%|██████████| 3/3 [01:24<00:00, 28.02s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [03:52<00:00, 77.59s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [04:36<00:00, 92.16s/it] \n",
      "Evaluating: 100%|██████████| 3/3 [05:11<00:00, 103.74s/it]\n",
      "100%|██████████| 5/5 [15:15<00:00, 183.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chave: question, Quantidade de elementos: 5\n",
      "Chave: ground_truth, Quantidade de elementos: 5\n",
      "Chave: contexts, Quantidade de elementos: 5\n",
      "Chave: answer, Quantidade de elementos: 5\n",
      "Chave: faithfulness, Quantidade de elementos: 5\n",
      "Chave: answer_relevancy, Quantidade de elementos: 5\n",
      "Chave: context_relevancy, Quantidade de elementos: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'data'\n",
    "\n",
    "# Adaptado do Ramon Simoes\n",
    "def create_dataset():\n",
    "    Context_articles = \"https://iirc-dataset.s3.us-west-2.amazonaws.com/context_articles.tar.gz\"\n",
    "    IIRC_test = \"https://drive.google.com/file/d/1hydwcbwN2-qoudoAbKIPjVruy0m8xjy2/view?usp=sharing\"\n",
    "\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        os.makedirs(DATA_DIR)\n",
    "\n",
    "    for url in [Context_articles, IIRC_test]:\n",
    "        if url.startswith('https://drive.google.com'):\n",
    "            filename = 'test_questions.json'\n",
    "            filepath = os.path.join(DATA_DIR, filename)\n",
    "            if not os.path.exists(filepath):\n",
    "                print(f\"Baixando {filename}...\")\n",
    "                gdown.download(IIRC_test, filepath, quiet=False, fuzzy=True)\n",
    "                print(f\"\\n{filename} baixado.\")\n",
    "        else:\n",
    "            filename = url.split('/')[-1]\n",
    "            filepath = os.path.join(DATA_DIR, filename)\n",
    "\n",
    "            if not os.path.exists(filepath):\n",
    "                print(f\"Baixando {filename}...\")\n",
    "                r = requests.get(url)\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                print(f\"{filename} baixado.\")\n",
    "\n",
    "            if filename.endswith('.tgz') or filename.endswith('.tar.gz'):\n",
    "                with tarfile.open(filepath, 'r:gz') as tar:\n",
    "                    members = [m for m in tar.getmembers() if not os.path.exists(os.path.join(DATA_DIR, m.name))]\n",
    "                    if len(members) > 0:\n",
    "                        print(f\"Extraindo {filename}...\")\n",
    "                        tar.extractall(DATA_DIR, members=members)\n",
    "                        print(f\"{filename} extraído.\")\n",
    "\n",
    "    context_articles = json.load(open(f\"{DATA_DIR}/context_articles.json\", \"r\"))\n",
    "    test_set = json.load(open(f\"{DATA_DIR}/test_questions.json\", \"r\"))\n",
    "    return context_articles, test_set\n",
    "\n",
    "# Pegado do Ramon Simoes\n",
    "def format_answer(item):\n",
    "    answer_type = item['answer']['type']\n",
    "    if answer_type == \"span\":\n",
    "        answer = \", \".join([answer_span['text'] for answer_span in item['answer'][\"answer_spans\"]])\n",
    "\n",
    "    elif answer_type == \"value\":\n",
    "        answer = \"{0} {1}\".format(item['answer']['answer_value'], item['answer']['answer_unit'])\n",
    "\n",
    "    elif answer_type == \"binary\":\n",
    "        answer = item['answer']['answer_value']\n",
    "\n",
    "    elif answer_type == \"none\":\n",
    "        answer = \"Not enough information\"\n",
    "\n",
    "    return answer\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", MarkupResemblesLocatorWarning)\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "    return soup.get_text()\n",
    "\n",
    "# Adaptado do Ramon Simoes\n",
    "def process_data(dataset, verbose = False):\n",
    "    documents = []\n",
    "    for item in tqdm(dataset):\n",
    "        contexts = []\n",
    "        for context in item[\"context\"]:\n",
    "            c = context[\"text\"]\n",
    "            contexts.append(remove_html_tags(c))\n",
    "            if verbose:\n",
    "                print(f\"\\n {item['question']}\")\n",
    "                print(contexts)\n",
    "\n",
    "        documents.append({\n",
    "            \"question\": item[\"question\"],\n",
    "            \"answer\": format_answer(item),\n",
    "            \"context\": contexts\n",
    "        })\n",
    "\n",
    "    print(f\"\\nQuantidade de questões: {len(documents)}\")\n",
    "    return documents\n",
    "\n",
    "context_articles, test_set = create_dataset()\n",
    "print(f\"\\nQuantidade de amostras do context_articles: {len(context_articles)}\")\n",
    "print(f\"\\nQuantidade de amostras do test_set: {len(test_set)}\")\n",
    "\n",
    "# Configuração do modelo e embedder\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(temperature=0, groq_api_key=GROQ_API_KEY, model_name=\"llama3-70b-8192\")\n",
    "embedder = HuggingFaceEmbeddings()\n",
    "\n",
    "metrics = [faithfulness, answer_relevancy, context_relevancy]\n",
    "\n",
    "documents = process_data(test_set)\n",
    "\n",
    "# Adicionar parâmetro para selecionar apenas as primeiras N questões\n",
    "N = 5  # Ajuste conforme necessário\n",
    "selected_documents = documents[:N]\n",
    "\n",
    "question = [document[\"question\"] for document in selected_documents]\n",
    "context = [document[\"context\"] for document in selected_documents]\n",
    "answer = [document[\"answer\"] for document in selected_documents]\n",
    "ground_truth = [document[\"answer\"] for document in selected_documents]\n",
    "\n",
    "dataset = Dataset.from_dict({\"question\": question, \"contexts\": context, \"answer\": answer, \"ground_truth\": ground_truth})\n",
    "\n",
    "# Adaptado do Ramon Simoes\n",
    "save_file = \"qa_data.pickle\"\n",
    "\n",
    "if os.path.exists(save_file):\n",
    "    with open(save_file, 'rb') as f:\n",
    "        qa = pickle.load(f)\n",
    "else:\n",
    "    qa = {'question': [], 'ground_truth': [], 'contexts': [], 'answer': [],\n",
    "          'faithfulness': [], 'answer_relevancy': [], 'context_relevancy': []}\n",
    "\n",
    "last_processed_index = 0\n",
    "with tqdm(total=len(dataset)) as pbar:\n",
    "    while last_processed_index < len(dataset):\n",
    "        q = Dataset.from_dict(dataset[last_processed_index: last_processed_index + 1])\n",
    "\n",
    "        if q['question'] in qa['question']:\n",
    "            last_processed_index += 1\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            qa['question'].append(q['question'])\n",
    "            qa['ground_truth'].append(q['ground_truth'])\n",
    "            qa['contexts'].append(q['contexts'])\n",
    "            qa['answer'].append(q['answer'])\n",
    "\n",
    "            result = evaluate(q, metrics, llm=llm, embeddings=embedder)\n",
    "\n",
    "            for r in result:\n",
    "                qa[r].append(result[r])\n",
    "\n",
    "            if len(qa['question']) % 5 == 0:\n",
    "                with open(save_file, 'wb') as f:\n",
    "                    pickle.dump(qa, f)\n",
    "\n",
    "                sleep_time = random.uniform(5, 20)\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "            last_processed_index += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nErro no indice {last_processed_index}: {e}\")\n",
    "            print(\"Rate limit excedido... esperando 120s\")\n",
    "            time.sleep(120)\n",
    "\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(qa, f)\n",
    "\n",
    "for chave, valor in qa.items():\n",
    "    quantidade = len(valor) if isinstance(valor, list) else 1\n",
    "    print(f'Chave: {chave}, Quantidade de elementos: {quantidade}')\n",
    "\n",
    "with open(save_file, 'rb') as f:\n",
    "    qa = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(qa)\n",
    "df.to_csv('resultado.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[What is Zeus know for in Greek mythology?]</td>\n",
       "      <td>[sky and thunder god]</td>\n",
       "      <td>[[he Palici the sons of Zeus, in Greek mytholo...</td>\n",
       "      <td>[sky and thunder god]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724556</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[How long had the First World War been over wh...</td>\n",
       "      <td>[5 years]</td>\n",
       "      <td>[[he became aide-de-camp to King Victor Emmanu...</td>\n",
       "      <td>[5 years]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651312</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[How old was Messe when the First World War st...</td>\n",
       "      <td>[30 years]</td>\n",
       "      <td>[[Messe was born in Mesagne, in the Province o...</td>\n",
       "      <td>[30 years]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929272</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[How long had Angela Scoular been acting profe...</td>\n",
       "      <td>[2 years]</td>\n",
       "      <td>[[Angela Scoular appeared as Ruby Bartlett in ...</td>\n",
       "      <td>[2 years]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818161</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[What is the capacity of the stadium where Bru...</td>\n",
       "      <td>[26,688]</td>\n",
       "      <td>[[Brunt returned to first-team action after ei...</td>\n",
       "      <td>[26,688]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.679309</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question           ground_truth  \\\n",
       "0        [What is Zeus know for in Greek mythology?]  [sky and thunder god]   \n",
       "1  [How long had the First World War been over wh...              [5 years]   \n",
       "2  [How old was Messe when the First World War st...             [30 years]   \n",
       "3  [How long had Angela Scoular been acting profe...              [2 years]   \n",
       "4  [What is the capacity of the stadium where Bru...               [26,688]   \n",
       "\n",
       "                                            contexts                 answer  \\\n",
       "0  [[he Palici the sons of Zeus, in Greek mytholo...  [sky and thunder god]   \n",
       "1  [[he became aide-de-camp to King Victor Emmanu...              [5 years]   \n",
       "2  [[Messe was born in Mesagne, in the Province o...             [30 years]   \n",
       "3  [[Angela Scoular appeared as Ruby Bartlett in ...              [2 years]   \n",
       "4  [[Brunt returned to first-team action after ei...               [26,688]   \n",
       "\n",
       "   faithfulness  answer_relevancy  context_relevancy  \n",
       "0           1.0          0.724556           1.000000  \n",
       "1           1.0          0.651312           1.000000  \n",
       "2           1.0          0.929272           1.000000  \n",
       "3           0.0          0.818161           0.333333  \n",
       "4           1.0          0.679309           1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas calculadas:\n",
      "Faithfulness: 0.8\n",
      "Answer Relevance: 0.7605219240133552\n",
      "Context Relevance: 0.8666666666666668\n"
     ]
    }
   ],
   "source": [
    "# Calcular e exibir métricas\n",
    "def calculate_metrics(df):\n",
    "    faithfulness_score = df['faithfulness'].mean()\n",
    "    answer_relevancy_score = df['answer_relevancy'].mean()\n",
    "    context_relevancy_score = df['context_relevancy'].mean()\n",
    "\n",
    "    print(f\"\\nMétricas calculadas:\")\n",
    "    print(f\"Faithfulness: {faithfulness_score}\")\n",
    "    print(f\"Answer Relevance: {answer_relevancy_score}\")\n",
    "    print(f\"Context Relevance: {context_relevancy_score}\")\n",
    "\n",
    "calculate_metrics(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia024_kernel",
   "language": "python",
   "name": "ia024_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
