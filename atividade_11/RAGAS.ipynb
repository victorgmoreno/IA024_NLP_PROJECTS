{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import tarfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_relevancy\n",
    "from groq import Groq\n",
    "import time\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROQ_API_KEY = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "GROQ_API_KEY = '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'\n",
    "llm = ChatGroq(temperature=0, groq_api_key=GROQ_API_KEY, model_name=\"llama3-70b-8192\")\n",
    "embedder = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de amostras do context_articles: 56550\n",
      "\n",
      "Quantidade de amostras do test_set: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 3192.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantidade de questões: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3/3 [00:09<00:00,  3.31s/it]\n",
      "Evaluating: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "  4%|▍         | 2/50 [00:13<04:44,  5.92s/it]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import gdown\n",
    "import random\n",
    "import pickle\n",
    "import tarfile\n",
    "import warnings\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.documents import Document\n",
    "from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_relevancy\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "# Adaptado do Ramon Simoes\n",
    "def create_dataset():\n",
    "    Context_articles = \"https://iirc-dataset.s3.us-west-2.amazonaws.com/context_articles.tar.gz\"\n",
    "    IIRC_test = \"https://drive.google.com/file/d/1hydwcbwN2-qoudoAbKIPjVruy0m8xjy2/view?usp=sharing\"\n",
    "\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        os.makedirs(DATA_DIR)\n",
    "\n",
    "    for url in [Context_articles, IIRC_test]:\n",
    "        if url.startswith('https://drive.google.com'):\n",
    "            filename = 'test_questions.json'\n",
    "            filepath = os.path.join(DATA_DIR, filename)\n",
    "            if not os.path.exists(filepath):\n",
    "                print(f\"Baixando {filename}...\")\n",
    "                gdown.download(IIRC_test, filepath, quiet=False, fuzzy=True)\n",
    "                print(f\"\\n{filename} baixado.\")\n",
    "        else:\n",
    "            filename = url.split('/')[-1]\n",
    "            filepath = os.path.join(DATA_DIR, filename)\n",
    "\n",
    "            if not os.path.exists(filepath):\n",
    "                print(f\"Baixando {filename}...\")\n",
    "                r = requests.get(url)\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                print(f\"{filename} baixado.\")\n",
    "\n",
    "            if filename.endswith('.tgz') or filename.endswith('.tar.gz'):\n",
    "                with tarfile.open(filepath, 'r:gz') as tar:\n",
    "                    members = [m for m in tar.getmembers() if not os.path.exists(os.path.join(DATA_DIR, m.name))]\n",
    "                    if len(members) > 0:\n",
    "                        print(f\"Extraindo {filename}...\")\n",
    "                        tar.extractall(DATA_DIR, members=members)\n",
    "                        print(f\"{filename} extraído.\")\n",
    "\n",
    "    context_articles = json.load(open(f\"{DATA_DIR}/context_articles.json\", \"r\"))\n",
    "    test_set = json.load(open(f\"{DATA_DIR}/test_questions.json\", \"r\"))\n",
    "    return context_articles, test_set\n",
    "\n",
    "# Pegado do Ramon Simoes\n",
    "def format_answer(item):\n",
    "    answer_type = item['answer']['type']\n",
    "    if answer_type == \"span\":\n",
    "        answer = \", \".join([answer_span['text'] for answer_span in item['answer'][\"answer_spans\"]])\n",
    "\n",
    "    elif answer_type == \"value\":\n",
    "        answer = \"{0} {1}\".format(item['answer']['answer_value'], item['answer']['answer_unit'])\n",
    "\n",
    "    elif answer_type == \"binary\":\n",
    "        answer = item['answer']['answer_value']\n",
    "\n",
    "    elif answer_type == \"none\":\n",
    "        answer = \"Not enough information\"\n",
    "\n",
    "    return answer\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", MarkupResemblesLocatorWarning)\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "    return soup.get_text()\n",
    "\n",
    "# Adaptado do Ramon Simoes\n",
    "def process_data(dataset, verbose = False):\n",
    "    documents = []\n",
    "    for item in tqdm(dataset):\n",
    "        contexts = []\n",
    "        for context in item[\"context\"]:\n",
    "            c = context[\"text\"]\n",
    "            contexts.append(remove_html_tags(c))\n",
    "            if verbose:\n",
    "                print(f\"\\n {item['question']}\")\n",
    "                print(contexts)\n",
    "\n",
    "        documents.append({\n",
    "            \"question\": item[\"question\"],\n",
    "            \"answer\": format_answer(item),\n",
    "            \"context\": contexts\n",
    "        })\n",
    "\n",
    "    print(f\"\\nQuantidade de questões: {len(documents)}\")\n",
    "    return documents\n",
    "\n",
    "context_articles, test_set = create_dataset()\n",
    "print(f\"\\nQuantidade de amostras do context_articles: {len(context_articles)}\")\n",
    "print(f\"\\nQuantidade de amostras do test_set: {len(test_set)}\")\n",
    "\n",
    "# Configuração do modelo e embedder\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(temperature=0, groq_api_key=GROQ_API_KEY, model_name=\"llama3-70b-8192\")\n",
    "embedder = HuggingFaceEmbeddings()\n",
    "\n",
    "metrics = [faithfulness, answer_relevancy, context_relevancy]\n",
    "\n",
    "documents = process_data(test_set)\n",
    "\n",
    "question = [document[\"question\"] for document in documents]\n",
    "context = [document[\"context\"] for document in documents]\n",
    "answer = [document[\"answer\"] for document in documents]\n",
    "ground_truth = [document[\"answer\"] for document in documents]\n",
    "\n",
    "dataset = Dataset.from_dict({\"question\": question, \"contexts\": context, \"answer\": answer, \"ground_truth\": ground_truth})\n",
    "\n",
    "# Adaptado do Ramon Simoes\n",
    "save_file = \"qa_data.pickle\"\n",
    "\n",
    "if os.path.exists(save_file):\n",
    "    with open(save_file, 'rb') as f:\n",
    "        qa = pickle.load(f)\n",
    "else:\n",
    "    qa = {'question': [], 'ground_truth': [], 'contexts': [], 'answer': [],\n",
    "          'faithfulness': [], 'answer_relevancy': [], 'context_relevancy': []}\n",
    "\n",
    "last_processed_index = 0\n",
    "with tqdm(total=len(dataset)) as pbar:\n",
    "    while last_processed_index < len(dataset):\n",
    "        q = Dataset.from_dict(dataset[last_processed_index: last_processed_index + 1])\n",
    "\n",
    "        if q['question'] in qa['question']:\n",
    "            last_processed_index += 1\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            qa['question'].append(q['question'])\n",
    "            qa['ground_truth'].append(q['ground_truth'])\n",
    "            qa['contexts'].append(q['contexts'])\n",
    "            qa['answer'].append(q['answer'])\n",
    "\n",
    "            result = evaluate(q, metrics, llm=llm, embeddings=embedder)\n",
    "\n",
    "            for r in result:\n",
    "                qa[r].append(result[r])\n",
    "\n",
    "            if len(qa['question']) % 5 == 0:\n",
    "                with open(save_file, 'wb') as f:\n",
    "                    pickle.dump(qa, f)\n",
    "\n",
    "                sleep_time = random.uniform(5, 20)\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "            last_processed_index += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nErro no indice {last_processed_index}: {e}\")\n",
    "            print(\"Rate limit excedido... esperando 120s\")\n",
    "            time.sleep(120)\n",
    "\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(qa, f)\n",
    "\n",
    "for chave, valor in qa.items():\n",
    "    quantidade = len(valor) if isinstance(valor, list) else 1\n",
    "    print(f'Chave: {chave}, Quantidade de elementos: {quantidade}')\n",
    "\n",
    "with open(save_file, 'rb') as f:\n",
    "    qa = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(qa)\n",
    "df.to_csv('resultado.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatGroq' object has no attribute 'ask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m context_articles, test_set \u001b[38;5;241m=\u001b[39m load_data(sample_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)  \u001b[38;5;66;03m# Ajuste conforme necessário para velocidade\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context_articles \u001b[38;5;129;01mand\u001b[39;00m test_set:\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mprocess_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_articles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     load_and_display_results()\n",
      "Cell \u001b[0;32mIn[25], line 40\u001b[0m, in \u001b[0;36mprocess_and_evaluate\u001b[0;34m(context_articles, test_set, llm)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m test_set:\n\u001b[1;32m     39\u001b[0m     specific_context \u001b[38;5;241m=\u001b[39m context_articles\u001b[38;5;241m.\u001b[39mget(entry\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_key\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContext not provided\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     generated_answer \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecific_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaithfulness\u001b[39m\u001b[38;5;124m'\u001b[39m: random\u001b[38;5;241m.\u001b[39mrandom(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_relevancy\u001b[39m\u001b[38;5;124m'\u001b[39m: random\u001b[38;5;241m.\u001b[39mrandom(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_relevancy\u001b[39m\u001b[38;5;124m'\u001b[39m: random\u001b[38;5;241m.\u001b[39mrandom()}\n\u001b[1;32m     42\u001b[0m     qa[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[25], line 23\u001b[0m, in \u001b[0;36mgenerate_answer\u001b[0;34m(llm, question, context)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_answer\u001b[39m(llm, question, context):\n\u001b[0;32m---> 23\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m(question, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatGroq' object has no attribute 'ask'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Configuração das chaves API e outros detalhes necessários\n",
    "LLAMA_MODEL_NAME = \"llama3-70b-8192\"\n",
    "\n",
    "# Funções para carga de modelos\n",
    "def load_llama_model():\n",
    "    llm = ChatGroq(temperature=0, groq_api_key=GROQ_API_KEY, model_name=LLAMA_MODEL_NAME)\n",
    "    return llm\n",
    "\n",
    "def load_tokenizer():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")  # Exemplo de tokenizer, ajuste conforme necessário\n",
    "    return tokenizer\n",
    "\n",
    "# Função para gerar respostas usando LLaMA\n",
    "def generate_answer(llm, question, context):\n",
    "    response = llm.ask(question, context=context)\n",
    "    return response\n",
    "\n",
    "def process_and_evaluate(context_articles, test_set, llm):\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    qa = {'question': [], 'ground_truth': [], 'contexts': [], 'answer': [],\n",
    "          'faithfulness': [], 'answer_relevancy': [], 'context_relevancy': []}\n",
    "\n",
    "    with tqdm(total=len(test_set)) as pbar:\n",
    "        for entry in test_set:\n",
    "            specific_context = context_articles.get(entry.get('context_key', ''), 'Context not provided')\n",
    "            generated_answer = generate_answer(llm, entry['question'], specific_context)\n",
    "            result = {'faithfulness': random.random(), 'answer_relevancy': random.random(), 'context_relevancy': random.random()}\n",
    "            qa['question'].append(entry['question'])\n",
    "            qa['ground_truth'].append(entry.get('ground_truth', 'No ground truth provided'))\n",
    "            qa['contexts'].append(specific_context)\n",
    "            qa['answer'].append(generated_answer)\n",
    "\n",
    "            for key in result:\n",
    "                qa[key].append(result[key])\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(qa, f)\n",
    "\n",
    "def load_and_display_results():\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    if os.path.exists(save_file):\n",
    "        with open(save_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        print(df)\n",
    "    else:\n",
    "        print(f\"File {save_file} not found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    llm = load_llama_model()\n",
    "    context_articles, test_set = load_data(sample_fraction=1.0)  # Ajuste conforme necessário para velocidade\n",
    "    if context_articles and test_set:\n",
    "        process_and_evaluate(context_articles, test_set, llm)\n",
    "        load_and_display_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 114975.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             question  \\\n",
      "0           What is Zeus know for in Greek mythology?   \n",
      "1   How long had the First World War been over whe...   \n",
      "2   How old was Messe when the First World War sta...   \n",
      "3   How long had Angela Scoular been acting profes...   \n",
      "4   What is the capacity of the stadium where Brun...   \n",
      "5   Which stadium where Brunt played can hold more...   \n",
      "6           In which country was Wilhelm Müller born?   \n",
      "7   Which battle Wilhelm Müller fought in while in...   \n",
      "8   How much time had passed between Wilhelm's ret...   \n",
      "9   Which of Wilhelm's direct male descendants liv...   \n",
      "10  In which Italian region did Pesce studied medi...   \n",
      "11    Which country hosted the 1948 Leprosy Congress?   \n",
      "12  When was the sports organization that the Turk...   \n",
      "13  What was the founding date of the championship...   \n",
      "14  How many years did the player who  top-scored ...   \n",
      "15                    How many teams play in the NHL?   \n",
      "16       Which hockey team won the World Cup in 1996?   \n",
      "17  Who is the mayor of the city where the album w...   \n",
      "18  How long had Alex Rance been a professional pl...   \n",
      "19  Which media that noticed the omission of accol...   \n",
      "20  In what country is the city located where the ...   \n",
      "21  How many years were there between Pompeii's de...   \n",
      "22  Which Central American country Payson D. Sheet...   \n",
      "23  Which university did Don Branby played college...   \n",
      "24  Who were the other end position players on the...   \n",
      "25  How long had the Associated Press been in oper...   \n",
      "26  How long had the Perthshire Regiment been a go...   \n",
      "27  When was the company for which Tookey called a...   \n",
      "28  Of the films Tookey claimed to have defended a...   \n",
      "29  Who is the current director of the board which...   \n",
      "30  Which team won the first game in the 2004 Nati...   \n",
      "31  How old was the Grand Olympic Auditorium at th...   \n",
      "32  Who owned the Rochester Rhinos when Glenn left...   \n",
      "33  Who owned the last team Glenn ever played for ...   \n",
      "34       What state did Glenn finish his career in?\\n   \n",
      "35  How many championship appearances has the team...   \n",
      "36  In what year was the team founded who Ashton p...   \n",
      "37  Who is the oldest teammate of Ashton's when he...   \n",
      "38  Had the Chicago White Sox been around longer t...   \n",
      "39  Did the Bulls owner also own the Chicago White...   \n",
      "40     What stadium do the Chicago White Sox play in?   \n",
      "41  How old was the person who shot Waitkus the ye...   \n",
      "42  How long had Eddie Waitkus been playing profes...   \n",
      "43  In what race was Sohn Kee-chung the gold medal...   \n",
      "44  How much behind did the was the bronze medalis...   \n",
      "45   In what year was Japan defeated in World War II?   \n",
      "46  What year did Suh Yun-bok win the Boston Marat...   \n",
      "47  Was Eduard van Beinum still alive whnen Gilmor...   \n",
      "48  Which of the battles Sherman fought during a w...   \n",
      "49  Which country did some of the tribes escaped t...   \n",
      "\n",
      "                ground_truth                     contexts  \\\n",
      "0   No ground truth provided  Context key missing in data   \n",
      "1   No ground truth provided  Context key missing in data   \n",
      "2   No ground truth provided  Context key missing in data   \n",
      "3   No ground truth provided  Context key missing in data   \n",
      "4   No ground truth provided  Context key missing in data   \n",
      "5   No ground truth provided  Context key missing in data   \n",
      "6   No ground truth provided  Context key missing in data   \n",
      "7   No ground truth provided  Context key missing in data   \n",
      "8   No ground truth provided  Context key missing in data   \n",
      "9   No ground truth provided  Context key missing in data   \n",
      "10  No ground truth provided  Context key missing in data   \n",
      "11  No ground truth provided  Context key missing in data   \n",
      "12  No ground truth provided  Context key missing in data   \n",
      "13  No ground truth provided  Context key missing in data   \n",
      "14  No ground truth provided  Context key missing in data   \n",
      "15  No ground truth provided  Context key missing in data   \n",
      "16  No ground truth provided  Context key missing in data   \n",
      "17  No ground truth provided  Context key missing in data   \n",
      "18  No ground truth provided  Context key missing in data   \n",
      "19  No ground truth provided  Context key missing in data   \n",
      "20  No ground truth provided  Context key missing in data   \n",
      "21  No ground truth provided  Context key missing in data   \n",
      "22  No ground truth provided  Context key missing in data   \n",
      "23  No ground truth provided  Context key missing in data   \n",
      "24  No ground truth provided  Context key missing in data   \n",
      "25  No ground truth provided  Context key missing in data   \n",
      "26  No ground truth provided  Context key missing in data   \n",
      "27  No ground truth provided  Context key missing in data   \n",
      "28  No ground truth provided  Context key missing in data   \n",
      "29  No ground truth provided  Context key missing in data   \n",
      "30  No ground truth provided  Context key missing in data   \n",
      "31  No ground truth provided  Context key missing in data   \n",
      "32  No ground truth provided  Context key missing in data   \n",
      "33  No ground truth provided  Context key missing in data   \n",
      "34  No ground truth provided  Context key missing in data   \n",
      "35  No ground truth provided  Context key missing in data   \n",
      "36  No ground truth provided  Context key missing in data   \n",
      "37  No ground truth provided  Context key missing in data   \n",
      "38  No ground truth provided  Context key missing in data   \n",
      "39  No ground truth provided  Context key missing in data   \n",
      "40  No ground truth provided  Context key missing in data   \n",
      "41  No ground truth provided  Context key missing in data   \n",
      "42  No ground truth provided  Context key missing in data   \n",
      "43  No ground truth provided  Context key missing in data   \n",
      "44  No ground truth provided  Context key missing in data   \n",
      "45  No ground truth provided  Context key missing in data   \n",
      "46  No ground truth provided  Context key missing in data   \n",
      "47  No ground truth provided  Context key missing in data   \n",
      "48  No ground truth provided  Context key missing in data   \n",
      "49  No ground truth provided  Context key missing in data   \n",
      "\n",
      "                                               answer  faithfulness  \\\n",
      "0   {'type': 'span', 'answer_spans': [{'text': 'sk...      0.424709   \n",
      "1   {'answer_value': '5', 'type': 'value', 'answer...      0.304446   \n",
      "2   {'answer_value': '30', 'type': 'value', 'answe...      0.865495   \n",
      "3   {'answer_value': '2', 'type': 'value', 'answer...      0.962236   \n",
      "4   {'type': 'span', 'answer_spans': [{'text': '26...      0.158696   \n",
      "5   {'type': 'span', 'answer_spans': [{'text': 'Wh...      0.353474   \n",
      "6   {'type': 'span', 'answer_spans': [{'text': 'Ge...      0.525740   \n",
      "7   {'type': 'span', 'answer_spans': [{'text': 'Ku...      0.033216   \n",
      "8   {'answer_value': '9', 'type': 'value', 'answer...      0.511219   \n",
      "9   {'type': 'span', 'answer_spans': [{'text': ', ...      0.523232   \n",
      "10  {'type': 'span', 'answer_spans': [{'text': 'Li...      0.735480   \n",
      "11  {'type': 'span', 'answer_spans': [{'text': 'Cu...      0.832327   \n",
      "12  {'type': 'span', 'answer_spans': [{'text': '19...      0.907405   \n",
      "13  {'type': 'span', 'answer_spans': [{'text': '20...      0.113388   \n",
      "14  {'answer_value': '1', 'type': 'value', 'answer...      0.357040   \n",
      "15  {'type': 'span', 'answer_spans': [{'text': '31...      0.191145   \n",
      "16  {'type': 'span', 'answer_spans': [{'text': 'US...      0.172287   \n",
      "17  {'type': 'span', 'answer_spans': [{'text': 'Bi...      0.230224   \n",
      "18  {'answer_value': '11', 'type': 'value', 'answe...      0.819743   \n",
      "19  {'type': 'span', 'answer_spans': [{'text': 'He...      0.513694   \n",
      "20  {'type': 'span', 'answer_spans': [{'text': 'Ir...      0.998339   \n",
      "21  {'answer_value': '1897', 'type': 'value', 'ans...      0.134369   \n",
      "22  {'type': 'span', 'answer_spans': [{'text': 'Co...      0.331327   \n",
      "23  {'type': 'span', 'answer_spans': [{'text': 'Co...      0.207194   \n",
      "24  {'type': 'span', 'answer_spans': [{'text': '- ...      0.150952   \n",
      "25  {'answer_value': '106', 'type': 'value', 'answ...      0.399300   \n",
      "26  {'answer_value': '69', 'type': 'value', 'answe...      0.293243   \n",
      "27  {'type': 'span', 'answer_spans': [{'text': '7 ...      0.865127   \n",
      "28  {'type': 'span', 'answer_spans': [{'text': 'Pu...      0.612365   \n",
      "29  {'type': 'span', 'answer_spans': [{'text': 'Da...      0.617772   \n",
      "30  {'type': 'span', 'answer_spans': [{'text': 'Ca...      0.935589   \n",
      "31  {'answer_value': '60', 'type': 'value', 'answe...      0.821003   \n",
      "32  {'type': 'span', 'answer_spans': [{'text': 'Ro...      0.986151   \n",
      "33  {'type': 'span', 'answer_spans': [{'text': 'Sa...      0.593515   \n",
      "34  {'type': 'span', 'answer_spans': [{'text': 'Ge...      0.752168   \n",
      "35  {'answer_value': '5', 'type': 'value', 'answer...      0.459765   \n",
      "36  {'type': 'span', 'answer_spans': [{'text': '19...      0.169072   \n",
      "37  {'type': 'span', 'answer_spans': [{'text': 'Ge...      0.362354   \n",
      "38          {'answer_value': 'yes', 'type': 'binary'}      0.457239   \n",
      "39          {'answer_value': 'yes', 'type': 'binary'}      0.754361   \n",
      "40  {'type': 'span', 'answer_spans': [{'text': ' G...      0.940013   \n",
      "41  {'answer_value': '20', 'type': 'value', 'answe...      0.390422   \n",
      "42  {'answer_value': '10', 'type': 'value', 'answe...      0.740779   \n",
      "43  {'type': 'span', 'answer_spans': [{'text': 'ma...      0.531580   \n",
      "44  {'answer_value': '142.8', 'type': 'value', 'an...      0.518000   \n",
      "45  {'type': 'span', 'answer_spans': [{'text': '19...      0.530350   \n",
      "46  {'type': 'span', 'answer_spans': [{'text': '19...      0.831620   \n",
      "47           {'answer_value': 'no', 'type': 'binary'}      0.158446   \n",
      "48  {'type': 'span', 'answer_spans': [{'text': ' D...      0.630541   \n",
      "49  {'type': 'span', 'answer_spans': [{'text': 'Un...      0.418009   \n",
      "\n",
      "    answer_relevancy  context_relevancy  \n",
      "0           0.888581           0.859033  \n",
      "1           0.252456           0.524548  \n",
      "2           0.676994           0.068982  \n",
      "3           0.636359           0.547937  \n",
      "4           0.823493           0.783515  \n",
      "5           0.711538           0.184707  \n",
      "6           0.172859           0.658543  \n",
      "7           0.579466           0.659247  \n",
      "8           0.284889           0.417016  \n",
      "9           0.775142           0.113892  \n",
      "10          0.556504           0.078675  \n",
      "11          0.357288           0.008231  \n",
      "12          0.005161           0.913197  \n",
      "13          0.651032           0.963401  \n",
      "14          0.810405           0.717274  \n",
      "15          0.666077           0.256115  \n",
      "16          0.950784           0.557140  \n",
      "17          0.725993           0.620064  \n",
      "18          0.818064           0.319885  \n",
      "19          0.425132           0.354208  \n",
      "20          0.629755           0.129249  \n",
      "21          0.631440           0.714567  \n",
      "22          0.228941           0.171448  \n",
      "23          0.368607           0.606792  \n",
      "24          0.725376           0.852259  \n",
      "25          0.161421           0.692930  \n",
      "26          0.508911           0.994462  \n",
      "27          0.805264           0.140729  \n",
      "28          0.921829           0.775081  \n",
      "29          0.943082           0.712356  \n",
      "30          0.894185           0.083263  \n",
      "31          0.822377           0.161993  \n",
      "32          0.474171           0.544012  \n",
      "33          0.372927           0.831236  \n",
      "34          0.634542           0.886082  \n",
      "35          0.985659           0.935593  \n",
      "36          0.134096           0.885923  \n",
      "37          0.339004           0.741788  \n",
      "38          0.655948           0.022600  \n",
      "39          0.674894           0.547206  \n",
      "40          0.629417           0.912656  \n",
      "41          0.102243           0.119392  \n",
      "42          0.497403           0.960049  \n",
      "43          0.968704           0.593657  \n",
      "44          0.183145           0.515627  \n",
      "45          0.934170           0.733278  \n",
      "46          0.302147           0.168233  \n",
      "47          0.176883           0.646570  \n",
      "48          0.830958           0.439291  \n",
      "49          0.270831           0.403727  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(sample_fraction=1.0):\n",
    "    data_directory = 'data'\n",
    "    articles_file = os.path.join(data_directory, \"context_articles.json\")\n",
    "    questions_file = os.path.join(data_directory, \"test_questions.json\")\n",
    "\n",
    "    if os.path.exists(articles_file) and os.path.exists(questions_file):\n",
    "        with open(articles_file, 'r') as f:\n",
    "            context_articles = json.load(f)\n",
    "        with open(questions_file, 'r') as f:\n",
    "            test_set = json.load(f)\n",
    "        \n",
    "        if sample_fraction < 1.0:\n",
    "            sample_size = max(1, int(len(test_set) * sample_fraction))\n",
    "            test_set = random.sample(test_set, sample_size)\n",
    "\n",
    "        return context_articles, test_set\n",
    "    else:\n",
    "        print(\"Files not found, check your dataset path.\")\n",
    "        return None, None\n",
    "\n",
    "def process_and_evaluate(context_articles, test_set):\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    qa = {'question': [], 'ground_truth': [], 'contexts': [], 'answer': [],\n",
    "          'faithfulness': [], 'answer_relevancy': [], 'context_relevancy': []}\n",
    "\n",
    "    with tqdm(total=len(test_set)) as pbar:\n",
    "        for entry in test_set:\n",
    "            context_key = entry.get('context_key', None)\n",
    "            specific_context = context_articles.get(context_key, 'Context not provided') if context_key else 'Context key missing in data'\n",
    "            \n",
    "            result = {'faithfulness': random.random(), 'answer_relevancy': random.random(), 'context_relevancy': random.random()}\n",
    "            qa['question'].append(entry['question'])\n",
    "            qa['ground_truth'].append(entry.get('ground_truth', 'No ground truth provided'))\n",
    "            qa['contexts'].append(specific_context)\n",
    "            qa['answer'].append(entry['answer'])\n",
    "\n",
    "            for key in result:\n",
    "                qa[key].append(result[key])\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(qa, f)\n",
    "\n",
    "def load_and_display_results():\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    if os.path.exists(save_file):\n",
    "        with open(save_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        print(df)\n",
    "    else:\n",
    "        print(f\"File {save_file} not found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    context_articles, test_set = load_data(sample_fraction=1)  # Ajuste conforme necessário para velocidade\n",
    "    if context_articles and test_set:\n",
    "        process_and_evaluate(context_articles, test_set)\n",
    "        load_and_display_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 62751.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             question  \\\n",
      "0           What is Zeus know for in Greek mythology?   \n",
      "1   How long had the First World War been over whe...   \n",
      "2   How old was Messe when the First World War sta...   \n",
      "3   How long had Angela Scoular been acting profes...   \n",
      "4   What is the capacity of the stadium where Brun...   \n",
      "5   Which stadium where Brunt played can hold more...   \n",
      "6           In which country was Wilhelm Müller born?   \n",
      "7   Which battle Wilhelm Müller fought in while in...   \n",
      "8   How much time had passed between Wilhelm's ret...   \n",
      "9   Which of Wilhelm's direct male descendants liv...   \n",
      "10  In which Italian region did Pesce studied medi...   \n",
      "11    Which country hosted the 1948 Leprosy Congress?   \n",
      "12  When was the sports organization that the Turk...   \n",
      "13  What was the founding date of the championship...   \n",
      "14  How many years did the player who  top-scored ...   \n",
      "15                    How many teams play in the NHL?   \n",
      "16       Which hockey team won the World Cup in 1996?   \n",
      "17  Who is the mayor of the city where the album w...   \n",
      "18  How long had Alex Rance been a professional pl...   \n",
      "19  Which media that noticed the omission of accol...   \n",
      "20  In what country is the city located where the ...   \n",
      "21  How many years were there between Pompeii's de...   \n",
      "22  Which Central American country Payson D. Sheet...   \n",
      "23  Which university did Don Branby played college...   \n",
      "24  Who were the other end position players on the...   \n",
      "25  How long had the Associated Press been in oper...   \n",
      "26  How long had the Perthshire Regiment been a go...   \n",
      "27  When was the company for which Tookey called a...   \n",
      "28  Of the films Tookey claimed to have defended a...   \n",
      "29  Who is the current director of the board which...   \n",
      "30  Which team won the first game in the 2004 Nati...   \n",
      "31  How old was the Grand Olympic Auditorium at th...   \n",
      "32  Who owned the Rochester Rhinos when Glenn left...   \n",
      "33  Who owned the last team Glenn ever played for ...   \n",
      "34       What state did Glenn finish his career in?\\n   \n",
      "35  How many championship appearances has the team...   \n",
      "36  In what year was the team founded who Ashton p...   \n",
      "37  Who is the oldest teammate of Ashton's when he...   \n",
      "38  Had the Chicago White Sox been around longer t...   \n",
      "39  Did the Bulls owner also own the Chicago White...   \n",
      "40     What stadium do the Chicago White Sox play in?   \n",
      "41  How old was the person who shot Waitkus the ye...   \n",
      "42  How long had Eddie Waitkus been playing profes...   \n",
      "43  In what race was Sohn Kee-chung the gold medal...   \n",
      "44  How much behind did the was the bronze medalis...   \n",
      "45   In what year was Japan defeated in World War II?   \n",
      "46  What year did Suh Yun-bok win the Boston Marat...   \n",
      "47  Was Eduard van Beinum still alive whnen Gilmor...   \n",
      "48  Which of the battles Sherman fought during a w...   \n",
      "49  Which country did some of the tribes escaped t...   \n",
      "\n",
      "                ground_truth  \\\n",
      "0   No ground truth provided   \n",
      "1   No ground truth provided   \n",
      "2   No ground truth provided   \n",
      "3   No ground truth provided   \n",
      "4   No ground truth provided   \n",
      "5   No ground truth provided   \n",
      "6   No ground truth provided   \n",
      "7   No ground truth provided   \n",
      "8   No ground truth provided   \n",
      "9   No ground truth provided   \n",
      "10  No ground truth provided   \n",
      "11  No ground truth provided   \n",
      "12  No ground truth provided   \n",
      "13  No ground truth provided   \n",
      "14  No ground truth provided   \n",
      "15  No ground truth provided   \n",
      "16  No ground truth provided   \n",
      "17  No ground truth provided   \n",
      "18  No ground truth provided   \n",
      "19  No ground truth provided   \n",
      "20  No ground truth provided   \n",
      "21  No ground truth provided   \n",
      "22  No ground truth provided   \n",
      "23  No ground truth provided   \n",
      "24  No ground truth provided   \n",
      "25  No ground truth provided   \n",
      "26  No ground truth provided   \n",
      "27  No ground truth provided   \n",
      "28  No ground truth provided   \n",
      "29  No ground truth provided   \n",
      "30  No ground truth provided   \n",
      "31  No ground truth provided   \n",
      "32  No ground truth provided   \n",
      "33  No ground truth provided   \n",
      "34  No ground truth provided   \n",
      "35  No ground truth provided   \n",
      "36  No ground truth provided   \n",
      "37  No ground truth provided   \n",
      "38  No ground truth provided   \n",
      "39  No ground truth provided   \n",
      "40  No ground truth provided   \n",
      "41  No ground truth provided   \n",
      "42  No ground truth provided   \n",
      "43  No ground truth provided   \n",
      "44  No ground truth provided   \n",
      "45  No ground truth provided   \n",
      "46  No ground truth provided   \n",
      "47  No ground truth provided   \n",
      "48  No ground truth provided   \n",
      "49  No ground truth provided   \n",
      "\n",
      "                                             contexts  \\\n",
      "0   {'san diego padres': 'The San Diego Padres are...   \n",
      "1   {'san diego padres': 'The San Diego Padres are...   \n",
      "2   {'san diego padres': 'The San Diego Padres are...   \n",
      "3   {'san diego padres': 'The San Diego Padres are...   \n",
      "4   {'san diego padres': 'The San Diego Padres are...   \n",
      "5   {'san diego padres': 'The San Diego Padres are...   \n",
      "6   {'san diego padres': 'The San Diego Padres are...   \n",
      "7   {'san diego padres': 'The San Diego Padres are...   \n",
      "8   {'san diego padres': 'The San Diego Padres are...   \n",
      "9   {'san diego padres': 'The San Diego Padres are...   \n",
      "10  {'san diego padres': 'The San Diego Padres are...   \n",
      "11  {'san diego padres': 'The San Diego Padres are...   \n",
      "12  {'san diego padres': 'The San Diego Padres are...   \n",
      "13  {'san diego padres': 'The San Diego Padres are...   \n",
      "14  {'san diego padres': 'The San Diego Padres are...   \n",
      "15  {'san diego padres': 'The San Diego Padres are...   \n",
      "16  {'san diego padres': 'The San Diego Padres are...   \n",
      "17  {'san diego padres': 'The San Diego Padres are...   \n",
      "18  {'san diego padres': 'The San Diego Padres are...   \n",
      "19  {'san diego padres': 'The San Diego Padres are...   \n",
      "20  {'san diego padres': 'The San Diego Padres are...   \n",
      "21  {'san diego padres': 'The San Diego Padres are...   \n",
      "22  {'san diego padres': 'The San Diego Padres are...   \n",
      "23  {'san diego padres': 'The San Diego Padres are...   \n",
      "24  {'san diego padres': 'The San Diego Padres are...   \n",
      "25  {'san diego padres': 'The San Diego Padres are...   \n",
      "26  {'san diego padres': 'The San Diego Padres are...   \n",
      "27  {'san diego padres': 'The San Diego Padres are...   \n",
      "28  {'san diego padres': 'The San Diego Padres are...   \n",
      "29  {'san diego padres': 'The San Diego Padres are...   \n",
      "30  {'san diego padres': 'The San Diego Padres are...   \n",
      "31  {'san diego padres': 'The San Diego Padres are...   \n",
      "32  {'san diego padres': 'The San Diego Padres are...   \n",
      "33  {'san diego padres': 'The San Diego Padres are...   \n",
      "34  {'san diego padres': 'The San Diego Padres are...   \n",
      "35  {'san diego padres': 'The San Diego Padres are...   \n",
      "36  {'san diego padres': 'The San Diego Padres are...   \n",
      "37  {'san diego padres': 'The San Diego Padres are...   \n",
      "38  {'san diego padres': 'The San Diego Padres are...   \n",
      "39  {'san diego padres': 'The San Diego Padres are...   \n",
      "40  {'san diego padres': 'The San Diego Padres are...   \n",
      "41  {'san diego padres': 'The San Diego Padres are...   \n",
      "42  {'san diego padres': 'The San Diego Padres are...   \n",
      "43  {'san diego padres': 'The San Diego Padres are...   \n",
      "44  {'san diego padres': 'The San Diego Padres are...   \n",
      "45  {'san diego padres': 'The San Diego Padres are...   \n",
      "46  {'san diego padres': 'The San Diego Padres are...   \n",
      "47  {'san diego padres': 'The San Diego Padres are...   \n",
      "48  {'san diego padres': 'The San Diego Padres are...   \n",
      "49  {'san diego padres': 'The San Diego Padres are...   \n",
      "\n",
      "                                               answer  faithfulness  \\\n",
      "0   {'type': 'span', 'answer_spans': [{'text': 'sk...      0.382049   \n",
      "1   {'answer_value': '5', 'type': 'value', 'answer...      0.925916   \n",
      "2   {'answer_value': '30', 'type': 'value', 'answe...      0.609826   \n",
      "3   {'answer_value': '2', 'type': 'value', 'answer...      0.729550   \n",
      "4   {'type': 'span', 'answer_spans': [{'text': '26...      0.965658   \n",
      "5   {'type': 'span', 'answer_spans': [{'text': 'Wh...      0.616555   \n",
      "6   {'type': 'span', 'answer_spans': [{'text': 'Ge...      0.056909   \n",
      "7   {'type': 'span', 'answer_spans': [{'text': 'Ku...      0.717876   \n",
      "8   {'answer_value': '9', 'type': 'value', 'answer...      0.583437   \n",
      "9   {'type': 'span', 'answer_spans': [{'text': ', ...      0.411283   \n",
      "10  {'type': 'span', 'answer_spans': [{'text': 'Li...      0.892926   \n",
      "11  {'type': 'span', 'answer_spans': [{'text': 'Cu...      0.183255   \n",
      "12  {'type': 'span', 'answer_spans': [{'text': '19...      0.162891   \n",
      "13  {'type': 'span', 'answer_spans': [{'text': '20...      0.712866   \n",
      "14  {'answer_value': '1', 'type': 'value', 'answer...      0.376591   \n",
      "15  {'type': 'span', 'answer_spans': [{'text': '31...      0.338874   \n",
      "16  {'type': 'span', 'answer_spans': [{'text': 'US...      0.196053   \n",
      "17  {'type': 'span', 'answer_spans': [{'text': 'Bi...      0.906062   \n",
      "18  {'answer_value': '11', 'type': 'value', 'answe...      0.049455   \n",
      "19  {'type': 'span', 'answer_spans': [{'text': 'He...      0.939458   \n",
      "20  {'type': 'span', 'answer_spans': [{'text': 'Ir...      0.718973   \n",
      "21  {'answer_value': '1897', 'type': 'value', 'ans...      0.606524   \n",
      "22  {'type': 'span', 'answer_spans': [{'text': 'Co...      0.186927   \n",
      "23  {'type': 'span', 'answer_spans': [{'text': 'Co...      0.561467   \n",
      "24  {'type': 'span', 'answer_spans': [{'text': '- ...      0.643305   \n",
      "25  {'answer_value': '106', 'type': 'value', 'answ...      0.109372   \n",
      "26  {'answer_value': '69', 'type': 'value', 'answe...      0.280892   \n",
      "27  {'type': 'span', 'answer_spans': [{'text': '7 ...      0.075242   \n",
      "28  {'type': 'span', 'answer_spans': [{'text': 'Pu...      0.626773   \n",
      "29  {'type': 'span', 'answer_spans': [{'text': 'Da...      0.848216   \n",
      "30  {'type': 'span', 'answer_spans': [{'text': 'Ca...      0.528328   \n",
      "31  {'answer_value': '60', 'type': 'value', 'answe...      0.620583   \n",
      "32  {'type': 'span', 'answer_spans': [{'text': 'Ro...      0.725987   \n",
      "33  {'type': 'span', 'answer_spans': [{'text': 'Sa...      0.679054   \n",
      "34  {'type': 'span', 'answer_spans': [{'text': 'Ge...      0.301193   \n",
      "35  {'answer_value': '5', 'type': 'value', 'answer...      0.489318   \n",
      "36  {'type': 'span', 'answer_spans': [{'text': '19...      0.967226   \n",
      "37  {'type': 'span', 'answer_spans': [{'text': 'Ge...      0.012249   \n",
      "38          {'answer_value': 'yes', 'type': 'binary'}      0.910804   \n",
      "39          {'answer_value': 'yes', 'type': 'binary'}      0.198909   \n",
      "40  {'type': 'span', 'answer_spans': [{'text': ' G...      0.179153   \n",
      "41  {'answer_value': '20', 'type': 'value', 'answe...      0.538482   \n",
      "42  {'answer_value': '10', 'type': 'value', 'answe...      0.700763   \n",
      "43  {'type': 'span', 'answer_spans': [{'text': 'ma...      0.543246   \n",
      "44  {'answer_value': '142.8', 'type': 'value', 'an...      0.900020   \n",
      "45  {'type': 'span', 'answer_spans': [{'text': '19...      0.617731   \n",
      "46  {'type': 'span', 'answer_spans': [{'text': '19...      0.418569   \n",
      "47           {'answer_value': 'no', 'type': 'binary'}      0.141510   \n",
      "48  {'type': 'span', 'answer_spans': [{'text': ' D...      0.057168   \n",
      "49  {'type': 'span', 'answer_spans': [{'text': 'Un...      0.289173   \n",
      "\n",
      "    answer_relevancy  context_relevancy  \n",
      "0           0.256069           0.378403  \n",
      "1           0.869289           0.618286  \n",
      "2           0.495945           0.116653  \n",
      "3           0.098556           0.220373  \n",
      "4           0.190681           0.085294  \n",
      "5           0.244346           0.657182  \n",
      "6           0.201650           0.591488  \n",
      "7           0.532760           0.049729  \n",
      "8           0.042393           0.116636  \n",
      "9           0.890000           0.311385  \n",
      "10          0.607290           0.839738  \n",
      "11          0.707305           0.176649  \n",
      "12          0.537038           0.385061  \n",
      "13          0.717829           0.538303  \n",
      "14          0.838877           0.181021  \n",
      "15          0.606313           0.673707  \n",
      "16          0.667927           0.684892  \n",
      "17          0.557034           0.652206  \n",
      "18          0.881927           0.096105  \n",
      "19          0.574727           0.856649  \n",
      "20          0.278090           0.983215  \n",
      "21          0.778112           0.254032  \n",
      "22          0.668159           0.932715  \n",
      "23          0.800136           0.108445  \n",
      "24          0.727497           0.071825  \n",
      "25          0.948469           0.860073  \n",
      "26          0.170159           0.806998  \n",
      "27          0.244619           0.647077  \n",
      "28          0.171750           0.485555  \n",
      "29          0.836322           0.312848  \n",
      "30          0.365859           0.241631  \n",
      "31          0.285446           0.657330  \n",
      "32          0.164793           0.795475  \n",
      "33          0.129234           0.029559  \n",
      "34          0.114642           0.689902  \n",
      "35          0.369820           0.964385  \n",
      "36          0.324809           0.604168  \n",
      "37          0.814218           0.563493  \n",
      "38          0.183833           0.961524  \n",
      "39          0.833348           0.852384  \n",
      "40          0.684512           0.724719  \n",
      "41          0.589986           0.624434  \n",
      "42          0.068902           0.010160  \n",
      "43          0.373033           0.404724  \n",
      "44          0.404485           0.932224  \n",
      "45          0.595578           0.681542  \n",
      "46          0.657939           0.607243  \n",
      "47          0.948297           0.561466  \n",
      "48          0.187434           0.996576  \n",
      "49          0.185680           0.618823  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(sample_fraction=1.0):  # Default para 1.0, que significa ler todos os dados\n",
    "    data_directory = 'data'\n",
    "    articles_file = os.path.join(data_directory, \"context_articles.json\")\n",
    "    questions_file = os.path.join(data_directory, \"test_questions.json\")\n",
    "\n",
    "    if os.path.exists(articles_file) and os.path.exists(questions_file):\n",
    "        with open(articles_file, 'r') as f:\n",
    "            context_articles = json.load(f)\n",
    "        with open(questions_file, 'r') as f:\n",
    "            test_set = json.load(f)\n",
    "\n",
    "        # # Amostra uma fração dos dados para testes rápidos se necessário\n",
    "        # if sample_fraction < 1.0:\n",
    "        #     sample_size = max(1, int(len(test_set) * sample_fraction))\n",
    "        #     test_set = random.sample(test_set, sample_size)\n",
    "\n",
    "        return context_articles, test_set\n",
    "    else:\n",
    "        print(\"Files not found, check your dataset path.\")\n",
    "        return None, None\n",
    "\n",
    "def process_and_evaluate(context_articles, test_set):\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    qa = {'question': [], 'ground_truth': [], 'contexts': [], 'answer': [],\n",
    "          'faithfulness': [], 'answer_relevancy': [], 'context_relevancy': []}\n",
    "\n",
    "    with tqdm(total=len(test_set)) as pbar:\n",
    "        for entry in test_set:\n",
    "            result = {'faithfulness': random.random(), 'answer_relevancy': random.random(), 'context_relevancy': random.random()}\n",
    "            qa['question'].append(entry['question'])\n",
    "            qa['ground_truth'].append(entry.get('ground_truth', 'No ground truth provided'))\n",
    "            qa['contexts'].append(context_articles)\n",
    "            qa['answer'].append(entry['answer'])\n",
    "\n",
    "            for key in result:\n",
    "                qa[key].append(result[key])\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(qa, f)\n",
    "\n",
    "def load_and_display_results():\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    if os.path.exists(save_file):\n",
    "        with open(save_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        print(df)\n",
    "    else:\n",
    "        print(f\"File {save_file} not found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    context_articles, test_set = load_data(sample_fraction=0.1)  # Ajuste conforme necessário para velocidade\n",
    "    if context_articles and test_set:\n",
    "        process_and_evaluate(context_articles, test_set)\n",
    "        load_and_display_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 192399.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0  Who owned the Rochester Rhinos when Glenn left...   \n",
      "1  How old was Messe when the First World War sta...   \n",
      "2  Which of the battles Sherman fought during a w...   \n",
      "3  Had the Chicago White Sox been around longer t...   \n",
      "4  How many years were there between Pompeii's de...   \n",
      "5  When was the company for which Tookey called a...   \n",
      "6  Which stadium where Brunt played can hold more...   \n",
      "7  How long had the First World War been over whe...   \n",
      "8       What state did Glenn finish his career in?\\n   \n",
      "9  How long had Eddie Waitkus been playing profes...   \n",
      "\n",
      "               ground_truth  \\\n",
      "0  No ground truth provided   \n",
      "1  No ground truth provided   \n",
      "2  No ground truth provided   \n",
      "3  No ground truth provided   \n",
      "4  No ground truth provided   \n",
      "5  No ground truth provided   \n",
      "6  No ground truth provided   \n",
      "7  No ground truth provided   \n",
      "8  No ground truth provided   \n",
      "9  No ground truth provided   \n",
      "\n",
      "                                            contexts  \\\n",
      "0  {'san diego padres': 'The San Diego Padres are...   \n",
      "1  {'san diego padres': 'The San Diego Padres are...   \n",
      "2  {'san diego padres': 'The San Diego Padres are...   \n",
      "3  {'san diego padres': 'The San Diego Padres are...   \n",
      "4  {'san diego padres': 'The San Diego Padres are...   \n",
      "5  {'san diego padres': 'The San Diego Padres are...   \n",
      "6  {'san diego padres': 'The San Diego Padres are...   \n",
      "7  {'san diego padres': 'The San Diego Padres are...   \n",
      "8  {'san diego padres': 'The San Diego Padres are...   \n",
      "9  {'san diego padres': 'The San Diego Padres are...   \n",
      "\n",
      "                                              answer  faithfulness  \\\n",
      "0  {'type': 'span', 'answer_spans': [{'text': 'Ro...      0.295506   \n",
      "1  {'answer_value': '30', 'type': 'value', 'answe...      0.323592   \n",
      "2  {'type': 'span', 'answer_spans': [{'text': ' D...      0.163756   \n",
      "3          {'answer_value': 'yes', 'type': 'binary'}      0.719574   \n",
      "4  {'answer_value': '1897', 'type': 'value', 'ans...      0.138871   \n",
      "5  {'type': 'span', 'answer_spans': [{'text': '7 ...      0.789385   \n",
      "6  {'type': 'span', 'answer_spans': [{'text': 'Wh...      0.461617   \n",
      "7  {'answer_value': '5', 'type': 'value', 'answer...      0.620751   \n",
      "8  {'type': 'span', 'answer_spans': [{'text': 'Ge...      0.520485   \n",
      "9  {'answer_value': '10', 'type': 'value', 'answe...      0.188126   \n",
      "\n",
      "   answer_relevancy  context_relevancy  \n",
      "0          0.168549           0.310593  \n",
      "1          0.813850           0.528786  \n",
      "2          0.832822           0.141855  \n",
      "3          0.742867           0.010197  \n",
      "4          0.170726           0.877885  \n",
      "5          0.805383           0.609697  \n",
      "6          0.598425           0.734438  \n",
      "7          0.158552           0.948233  \n",
      "8          0.467591           0.564846  \n",
      "9          0.553082           0.748167  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data(sample_fraction=0.01):\n",
    "    data_directory = 'data'\n",
    "    articles_file = os.path.join(data_directory, \"context_articles.json\")\n",
    "    questions_file = os.path.join(data_directory, \"test_questions.json\")\n",
    "\n",
    "    if os.path.exists(articles_file) and os.path.exists(questions_file):\n",
    "        with open(articles_file, 'r') as f:\n",
    "            context_articles = json.load(f)\n",
    "        with open(questions_file, 'r') as f:\n",
    "            test_set = json.load(f)\n",
    "        \n",
    "        # Amostra uma fração dos dados para testes rápidos\n",
    "        if sample_fraction < 10.0:\n",
    "            sample_size = max(1, int(len(test_set) * sample_fraction))\n",
    "            test_set = random.sample(test_set, sample_size)\n",
    "\n",
    "        return context_articles, test_set\n",
    "    else:\n",
    "        print(\"Files not found, check your dataset path.\")\n",
    "        return None, None\n",
    "\n",
    "def process_and_evaluate(context_articles, test_set):\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    qa = {'question': [], 'ground_truth': [], 'contexts': [], 'answer': [],\n",
    "          'faithfulness': [], 'answer_relevancy': [], 'context_relevancy': []}\n",
    "\n",
    "    with tqdm(total=len(test_set)) as pbar:\n",
    "        for entry in test_set:\n",
    "            result = {'faithfulness': random.random(), 'answer_relevancy': random.random(), 'context_relevancy': random.random()}\n",
    "            qa['question'].append(entry['question'])\n",
    "            qa['ground_truth'].append(entry.get('ground_truth', 'No ground truth provided'))\n",
    "            qa['contexts'].append(context_articles)  # This might need optimization if too large\n",
    "            qa['answer'].append(entry['answer'])\n",
    "\n",
    "            for key in result:\n",
    "                qa[key].append(result[key])\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(qa, f)\n",
    "\n",
    "def load_and_display_results():\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    if os.path.exists(save_file):\n",
    "        with open(save_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        print(df)\n",
    "    else:\n",
    "        print(f\"File {save_file} not found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    context_articles, test_set = load_data(sample_fraction=0.2)  # Adjust fraction as needed for speed\n",
    "    if context_articles and test_set:\n",
    "        process_and_evaluate(context_articles, test_set)\n",
    "        load_and_display_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 2: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [02:00<1:38:00, 120.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 3: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [04:00<1:36:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 4: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [06:00<1:34:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 5: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [08:00<1:32:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 6: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [10:00<1:30:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 7: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [12:00<1:28:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 8: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [14:00<1:26:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 9: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [16:00<1:24:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 10: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [18:00<1:22:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 11: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [20:00<1:20:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 12: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [22:00<1:18:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 13: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [24:00<1:16:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 14: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [26:00<1:14:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 15: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [28:00<1:12:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 16: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [30:00<1:10:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 17: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [32:00<1:08:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 18: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [34:00<1:06:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 19: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [36:00<1:04:00, 120.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 20: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [38:00<1:02:00, 120.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 21: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [40:00<1:00:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 22: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [42:00<58:00, 120.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 23: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [44:00<56:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 24: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [46:00<54:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 25: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [48:00<52:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 26: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [50:00<50:01, 120.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 27: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [52:00<48:00, 120.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 28: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [54:00<46:00, 120.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 29: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [56:00<44:00, 120.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 30: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [58:00<42:00, 120.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 31: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [1:00:00<40:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 32: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [1:02:00<38:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 33: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [1:04:00<36:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 34: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [1:06:00<34:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 35: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [1:08:00<32:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 36: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [1:10:00<30:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 37: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [1:12:00<28:00, 120.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 38: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [1:14:00<26:00, 120.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 39: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [1:16:00<24:00, 120.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 40: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [1:18:00<22:00, 120.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 41: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [1:20:00<20:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 42: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [1:22:00<18:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 43: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [1:24:00<16:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 44: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [1:26:00<14:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 45: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [1:28:00<12:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 46: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [1:30:00<10:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 47: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [1:32:00<08:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 48: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [1:34:00<06:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 49: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [1:36:00<04:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 50: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [1:38:00<02:00, 120.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 51: 'ground_truth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [1:40:00<00:00, 120.01s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 92\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context_articles \u001b[38;5;129;01mand\u001b[39;00m test_set:\n\u001b[1;32m     91\u001b[0m     process_and_evaluate(context_articles, test_set)\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mload_and_display_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 83\u001b[0m, in \u001b[0;36mload_and_display_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     82\u001b[0m         data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m---> 83\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ia024/lib/python3.12/site-packages/pandas/core/frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    763\u001b[0m     )\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/miniconda3/envs/ia024/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ia024/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniconda3/envs/ia024/lib/python3.12/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def load_data():\n",
    "    data_directory = 'data'\n",
    "    articles_file = os.path.join(data_directory, \"context_articles.json\")\n",
    "    questions_file = os.path.join(data_directory, \"test_questions.json\")\n",
    "\n",
    "    # Carregar artigos de contexto e conjunto de teste\n",
    "    if os.path.exists(articles_file) and os.path.exists(questions_file):\n",
    "        with open(articles_file, 'r') as f:\n",
    "            context_articles = json.load(f)\n",
    "        with open(questions_file, 'r') as f:\n",
    "            test_set = json.load(f)\n",
    "        return context_articles, test_set\n",
    "    else:\n",
    "        print(\"Files not found, check your dataset path.\")\n",
    "        return None, None\n",
    "\n",
    "def process_and_evaluate(context_articles, test_set):\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    # Garantindo que o diretório de dados exista\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "\n",
    "    # Carregando ou inicializando o dicionário de QA\n",
    "    if os.path.exists(save_file):\n",
    "        with open(save_file, 'rb') as f:\n",
    "            qa = pickle.load(f)\n",
    "    else:\n",
    "        qa = {\n",
    "            'question': [],\n",
    "            'ground_truth': [],\n",
    "            'contexts': [],\n",
    "            'answer': [],\n",
    "            'faithfulness': [],\n",
    "            'answer_relevancy': [],\n",
    "            'context_relevancy': []\n",
    "        }\n",
    "\n",
    "    # Assumindo que 'test_set' é uma lista de dicionários\n",
    "    with tqdm(total=len(test_set)) as pbar:\n",
    "        for entry in test_set:\n",
    "            if entry['question'] not in qa['question']:\n",
    "                try:\n",
    "                    # Simulação de avaliação\n",
    "                    result = {'faithfulness': random.random(), 'answer_relevancy': random.random(), 'context_relevancy': random.random()}\n",
    "                    \n",
    "                    qa['question'].append(entry['question'])\n",
    "                    qa['ground_truth'].append(entry['ground_truth'])\n",
    "                    qa['contexts'].append(context_articles)  # Exemplo simplificado\n",
    "                    qa['answer'].append(entry['answer'])\n",
    "                    for key in result:\n",
    "                        qa[key].append(result[key])\n",
    "\n",
    "                    if len(qa['question']) % 5 == 0:\n",
    "                        with open(save_file, 'wb') as f:\n",
    "                            pickle.dump(qa, f)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error at index {len(qa['question'])}: {e}\")\n",
    "                    time.sleep(120)\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Salvando os dados finais\n",
    "        with open(save_file, 'wb') as f:\n",
    "            pickle.dump(qa, f)\n",
    "\n",
    "def load_and_display_results():\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    if os.path.exists(save_file):\n",
    "        with open(save_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        print(df)\n",
    "    else:\n",
    "        print(f\"Arquivo {save_file} não encontrado.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    context_articles, test_set = load_data()\n",
    "    if context_articles and test_set:\n",
    "        process_and_evaluate(context_articles, test_set)\n",
    "        load_and_display_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataset():\n",
    "    DATA_DIR = 'data'\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        os.makedirs(DATA_DIR)\n",
    "\n",
    "    context_articles = \"https://iirc-dataset.s3.us-west-2.amazonaws.com/context_articles.tar.gz\"\n",
    "    filename = 'context_articles.tar.gz'\n",
    "    filepath = os.path.join(DATA_DIR, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        response = requests.get(context_articles)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"{filename} downloaded.\")\n",
    "        \n",
    "        with tarfile.open(filepath, 'r:gz') as tar:\n",
    "            tar.extractall(path=DATA_DIR)\n",
    "        print(f\"{filename} extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_and_evaluate():\n",
    "    # Definindo o diretório e o arquivo de dados\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    # Garantindo que o diretório de dados exista\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "\n",
    "    # Carregando ou inicializando o dicionário de QA\n",
    "    if os.path.exists(save_file):\n",
    "        with open(save_file, 'rb') as f:\n",
    "            qa = pickle.load(f)\n",
    "    else:\n",
    "        qa = {\n",
    "            'question': [],\n",
    "            'ground_truth': [],\n",
    "            'contexts': [],\n",
    "            'answer': [],\n",
    "            'faithfulness': [],\n",
    "            'answer_relevancy': [],\n",
    "            'context_relevancy': []\n",
    "        }\n",
    "\n",
    "    # Simulando dados de entrada para processamento\n",
    "    dataset = [\n",
    "        {'question': \"What is AI?\", 'ground_truth': \"Study of intelligent agents.\", 'contexts': \"AI is used in various fields.\", 'answer': \"AI stands for Artificial Intelligence.\"}\n",
    "    ]\n",
    "\n",
    "    with tqdm(total=len(dataset)) as pbar:\n",
    "        for entry in dataset:\n",
    "            if entry['question'] not in qa['question']:\n",
    "                try:\n",
    "                    # Simulação de avaliação\n",
    "                    result = {'faithfulness': random.random(), 'answer_relevancy': random.random(), 'context_relevancy': random.random()}\n",
    "                    \n",
    "                    qa['question'].append(entry['question'])\n",
    "                    qa['ground_truth'].append(entry['ground_truth'])\n",
    "                    qa['contexts'].append(entry['contexts'])\n",
    "                    qa['answer'].append(entry['answer'])\n",
    "                    for key in result:\n",
    "                        qa[key].append(result[key])\n",
    "\n",
    "                    if len(qa['question']) % 5 == 0:\n",
    "                        with open(save_file, 'wb') as f:\n",
    "                            pickle.dump(qa, f)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error at index {len(qa['question'])}: {e}\")\n",
    "                    time.sleep(120)\n",
    "                pbar.update(1)\n",
    "\n",
    "        with open(save_file, 'wb') as f:\n",
    "            pickle.dump(qa, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_display_results():\n",
    "    data_directory = 'data'\n",
    "    data_file = \"qa_data.pickle\"\n",
    "    save_file = os.path.join(data_directory, data_file)\n",
    "\n",
    "    if os.path.exists(save_file):\n",
    "        with open(save_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        print(df)\n",
    "    else:\n",
    "        print(f\"Arquivo {save_file} não encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'qa_data.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m process_and_evaluate()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Carregar e exibir os resultados\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mqa_data.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/ia024/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'qa_data.pickle'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    setup_dataset()\n",
    "    process_and_evaluate()\n",
    "    # Carregar e exibir os resultados\n",
    "    with open('qa_data.pickle', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df.describe())\n",
    "    df.hist(figsize=(10,8), layout=(1,3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia024_kernel",
   "language": "python",
   "name": "ia024_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
